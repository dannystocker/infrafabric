#!/usr/bin/env python3
"""
Mini Task Runner

Purpose
-------
Help route small, localized tasks (generated by a "Max" / researcher-grade
agent) to lighter models such as Codex Mini, while forcing each mini task
to decide whether it can complete the work or must escalate back to a
higher-capacity agent.

It does NOT call a model directly. Instead, it:
  - Loads a JSON worklist (M1: MINI_TASKS_JSON).
  - Lists available tasks.
  - Prints a ready-to-paste prompt for a selected task, including its inputs
    and a required JSON output schema.

This makes it easy to:
  - Let a high-effort model decompose work.
  - Use a cheaper model to actually perform the small steps.
  - Preserve IF.TTT-style discipline on when to escalate blockers.

JSON schema (expected for tasks)
--------------------------------
{
  "version": "1.0",
  "generated_at": "<ISO8601>",
  "context": { ... },
  "mini_tasks": [
    {
      "id": "T1",
      "kind": "yaml_edit",
      "target_file": "dependency_map.yaml",
      "summary": "Short description",
      "inputs": { ... },
      "suggested_prompt_for_mini": "Instruction string"
    }
  ]
}

Usage
-----
From repo root (/home/setup/infrafabric):

  # List tasks in mini_tasks.json
  python3 tools/mini_task_runner.py --tasks-file mini_tasks.json --list

  # Show full prompt for a specific task
  python3 tools/mini_task_runner.py --tasks-file mini_tasks.json --id T1

  # Run a built-in demo on a simple function task
  python3 tools/mini_task_runner.py --demo
"""

from __future__ import annotations

import argparse
import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional


@dataclass
class MiniTask:
    id: str
    kind: str
    target_file: Optional[str]
    summary: str
    inputs: Dict[str, Any]
    suggested_prompt_for_mini: str


def load_tasks(tasks_path: Path) -> Dict[str, Any]:
    if not tasks_path.exists():
        raise FileNotFoundError(f"Tasks file not found: {tasks_path}")
    with tasks_path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    if "mini_tasks" not in data or not isinstance(data["mini_tasks"], list):
        raise ValueError("Invalid tasks JSON: missing 'mini_tasks' list")
    return data


def parse_mini_tasks(raw: Dict[str, Any]) -> List[MiniTask]:
    tasks: List[MiniTask] = []
    for entry in raw.get("mini_tasks", []):
        try:
            tasks.append(
                MiniTask(
                    id=str(entry.get("id", "")),
                    kind=str(entry.get("kind", "")),
                    target_file=entry.get("target_file"),
                    summary=str(entry.get("summary", "")),
                    inputs=entry.get("inputs", {}) or {},
                    suggested_prompt_for_mini=str(
                        entry.get("suggested_prompt_for_mini", "")
                    ),
                )
            )
        except Exception as exc:
            raise ValueError(f"Invalid mini task entry: {entry!r}") from exc
    return tasks


def render_prompt(task: MiniTask, include_inputs: bool = True) -> str:
    """
    Render a ready-to-paste prompt for a smaller model.

    The prompt includes:
      - Task summary and target file.
      - JSON-encoded inputs (if requested).
      - Task-specific instructions.
      - A REQUIRED JSON output format that forces the model to:
          * state whether it can complete the task locally,
          * decide if escalation back to a higher-capacity agent is needed,
          * provide a TTT-style decision record with reasoning and confidence.
    """
    lines: List[str] = []
    lines.append(f"# Mini Task {task.id}: {task.summary}")
    lines.append("")
    if task.target_file:
        lines.append(f"Target file: {task.target_file}")
        lines.append("")
    if include_inputs and task.inputs:
        lines.append("Context inputs (JSON):")
        lines.append("```json")
        lines.append(json.dumps(task.inputs, indent=2, sort_keys=True))
        lines.append("```")
        lines.append("")
    lines.append("Instruction for the smaller model:")
    lines.append("")
    lines.append(task.suggested_prompt_for_mini.strip())
    lines.append("")
    lines.append("You MUST produce your final answer in the following JSON format,")
    lines.append("and NOTHING else (no extra commentary outside the JSON):")
    lines.append("")
    lines.append("```json")
    lines.append(json.dumps(
        {
            "decision": {
                "status": "<completed|escalate_to_max|blocked>",
                "reason": "Short explanation of why you can or cannot fully complete this task.",
                "confidence": 0.0
            },
            "if_ttt_decision_record": {
                "claim": "One-sentence claim about whether this task was completed locally or needs escalation.",
                "evidence": [
                    "Key cues from the task or inputs that informed your decision (e.g., missing files, ambiguous requirements, or external constraints)."
                ],
                "protocols": ["IF.TTT.AUTOSYNC"],
                "confidence": 0.0
            },
            "result": {
                "output": "For completed: the actual code / YAML / text you are returning. For escalate_to_max or blocked: optional partial work or an empty string.",
                "notes": "Optional notes for the higher-capacity agent or human operator."
            }
        },
        indent=2,
        sort_keys=False
    ))
    lines.append("```")
    lines.append("")
    lines.append("Rules:")
    lines.append("- If you are confident you fully completed the task, set status to \"completed\".")
    lines.append("- If you cannot complete the task safely or it clearly exceeds your scope, set status to \"escalate_to_max\".")
    lines.append("- If you are blocked by missing information or contradictions, set status to \"blocked\".")
    lines.append("- Always fill in the if_ttt_decision_record fields to explain your decision and evidence.")
    return "\n".join(lines)


def list_tasks(tasks: List[MiniTask]) -> None:
    if not tasks:
        print("No mini tasks found.")
        return
    print(f"{len(tasks)} mini task(s) available:")
    for t in tasks:
        target = f" ({t.target_file})" if t.target_file else ""
        print(f"- {t.id}: [{t.kind}]{target} {t.summary}")


def run_demo() -> None:
    """Demo mode: simple function refactor task."""
    demo_data = {
        "version": "1.0",
        "generated_at": "2025-12-06T00:00:00Z",
        "context": {
            "repo_root": "/home/setup/infrafabric",
            "note": "Demo only; no real files touched.",
        },
        "mini_tasks": [
            {
                "id": "T_demo_1",
                "kind": "python_refactor",
                "target_file": "demo_sample.py",
                "summary": "Refactor a simple square() function for clarity and add a docstring.",
                "inputs": {
                    "original_function": "def square(x):\n    return x*x\n",
                    "requirements": [
                        "Add a short docstring.",
                        "Keep behavior identical.",
                        "Use type hints.",
                    ],
                },
                "suggested_prompt_for_mini": (
                    "You are a focused Python refactoring assistant. "
                    "Rewrite the provided square(x) function so that it:\n"
                    "1) Includes a concise docstring.\n"
                    "2) Uses type hints.\n"
                    "3) Preserves exact behavior.\n"
                    "Return ONLY the rewritten function, no extra commentary."
                ),
            }
        ],
    }

    tasks = parse_mini_tasks(demo_data)
    list_tasks(tasks)
    print("\n--- Prompt for first demo task ---\n")
    demo_task = tasks[0]
    print(render_prompt(demo_task, include_inputs=True))


def main(argv: Optional[List[str]] = None) -> None:
    parser = argparse.ArgumentParser(
        description="Mini Task Runner - inspect and render mini-task prompts."
    )
    parser.add_argument(
        "--tasks-file",
        type=str,
        default="mini_tasks.json",
        help="Path to JSON file containing mini_tasks (default: mini_tasks.json)",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="List available mini tasks.",
    )
    parser.add_argument(
        "--id",
        type=str,
        help="ID of a specific mini task to render.",
    )
    parser.add_argument(
        "--demo",
        action="store_true",
        help="Run built-in demo using a simple function task.",
    )

    args = parser.parse_args(argv)

    if args.demo:
        run_demo()
        return

    tasks_path = Path(args.tasks_file)
    data = load_tasks(tasks_path)
    tasks = parse_mini_tasks(data)

    if args.list:
        list_tasks(tasks)
        # If only listing, we can exit here unless an ID was also requested
        if not args.id:
            return

    if args.id:
        match = next((t for t in tasks if t.id == args.id), None)
        if not match:
            raise SystemExit(f"No mini task with id={args.id!r} found in {tasks_path}")
        print(render_prompt(match, include_inputs=True))
    elif not args.list:
        # No explicit action; show usage hint
        print("No action specified. Use --list to list tasks, --id to show one, or --demo.")


if __name__ == "__main__":
    main()
