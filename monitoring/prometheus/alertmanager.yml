global:
  resolve_timeout: 5m
  slack_api_url: '${SLACK_WEBHOOK_URL}'
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

templates:
  - '/etc/alertmanager/templates/alerts.tmpl'

route:
  # Root route - default receiver
  receiver: 'default'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  # P0 Critical - immediate escalation
  routes:
    - match:
        severity: critical
      receiver: 'p0_critical'
      group_wait: 0s
      group_interval: 30s
      repeat_interval: 1m
      continue: true

    # P1 High - urgent but not immediate
    - match:
        severity: high
      receiver: 'p1_high'
      group_wait: 5s
      group_interval: 5m
      repeat_interval: 4h
      continue: true

    # P2 Medium - informational with batching
    - match:
        severity: medium
      receiver: 'p2_medium'
      group_wait: 1m
      group_interval: 30m
      repeat_interval: 24h
      continue: false

receivers:
  # P0 Critical: PagerDuty + Slack #incidents
  - name: 'p0_critical'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        description: 'InfraFabric Critical Alert: {{ .GroupLabels.alertname }}'
        details:
          firing: '{{ template "pagerduty.default.instances" .Alerts.Firing }}'
        client: 'Prometheus AlertManager'
        client_url: '{{ .ExternalURL }}'
    slack_configs:
      - channel: '#incidents'
        title: 'CRITICAL ALERT: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        actions:
          - type: button
            text: 'View Runbook'
            url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
          - type: button
            text: 'View Dashboard'
            url: '{{ .ExternalURL }}/graph'
        footer: 'InfraFabric Monitoring | {{ .GroupLabels.component }}'
        ts: '{{ (index .Alerts 0).StartsAt.Unix }}'

  # P1 High: Slack #alerts + Email (within 5min)
  - name: 'p1_high'
    slack_configs:
      - channel: '#alerts'
        title: 'HIGH ALERT: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts -}}
          *{{ .Labels.alertname }}*
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          Impact: {{ .Annotations.impact }}
          {{ end }}
        send_resolved: true
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
        actions:
          - type: button
            text: 'Runbook'
            url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
        footer: 'InfraFabric | {{ .GroupLabels.component }}'
        ts: '{{ (index .Alerts 0).StartsAt.Unix }}'
    email_configs:
      - to: '${ALERTS_EMAIL}'
        from: '${ALERTMANAGER_FROM_EMAIL}'
        smarthost: '${SMTP_HOST}}:{{ .SMTP_PORT }}'
        auth_username: '${SMTP_USER}'
        auth_password: '${SMTP_PASSWORD}'
        headers:
          Subject: 'InfraFabric High Alert: {{ .GroupLabels.alertname }}'
          From: 'Prometheus AlertManager <alerts@infrafabric.local>'
        html: |
          <h2>{{ .GroupLabels.alertname }} - HIGH SEVERITY</h2>
          {{ range .Alerts }}
          <p><strong>Summary:</strong> {{ .Annotations.summary }}</p>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Impact:</strong> {{ .Annotations.impact }}</p>
          <p><strong>Action Items:</strong><pre>{{ .Annotations.action }}</pre></p>
          <p><a href="{{ .Annotations.runbook_url }}">View Runbook</a></p>
          {{ end }}

  # P2 Medium: Slack #monitoring (batched every 30min)
  - name: 'p2_medium'
    slack_configs:
      - channel: '#monitoring'
        title: 'MEDIUM ALERT: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts -}}
          {{ .Labels.alertname }}: {{ .Annotations.summary }}
          {{ end }}
        send_resolved: false
        color: '#FF9900'
        footer: 'InfraFabric | {{ .GroupLabels.component }}'

  # Default receiver (should not be used)
  - name: 'default'
    slack_configs:
      - channel: '#monitoring'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'

inhibit_rules:
  # Inhibit P1 alerts when P0 is firing (reduce noise)
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'high'
    equal: ['alertname', 'cluster']

  # Inhibit P2 alerts when P0 is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'medium'
    equal: ['alertname', 'cluster']

  # Inhibit P2 alerts when P1 is firing for same component
  - source_match:
      severity: 'high'
    target_match:
      severity: 'medium'
    equal: ['component']
